{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, time\n",
    "from typing import List, Dict, Tuple\n",
    "from pandas import DataFrame\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class TimeBlock(BaseModel):\n",
    "    start_time: time\n",
    "    end_time: time\n",
    "    id: str\n",
    "    demand_key_code: int\n",
    "\n",
    "\n",
    "class TimeBlocks:\n",
    "    def __init__(self, time_blocks: List[TimeBlock]):\n",
    "        self.time_blocks = time_blocks\n",
    "\n",
    "    def get_time_block_ids(self) -> List[str]:\n",
    "        time_block_ids = []\n",
    "        for time_block in self.time_blocks:\n",
    "            time_block_ids.append(time_block.id)\n",
    "        return time_block_ids\n",
    "\n",
    "    def get_time_block_to_start_time(self) -> Dict[str, time]:\n",
    "        time_block_to_start_time: Dict[str, time] = {}\n",
    "        for time_block in self.time_blocks:\n",
    "            time_block_to_start_time[time_block.id] = time_block.start_time\n",
    "\n",
    "        return time_block_to_start_time\n",
    "\n",
    "    def to_data_frame(self):\n",
    "        return DataFrame([time_block.__dict__ for time_block in self.time_blocks])\n",
    "    \n",
    "def load_time_block() -> TimeBlocks:\n",
    "        usecols = ['id', 'start_time', 'end_time', 'demand_key_code']\n",
    "        df_time_block = pd.read_csv('time_block.txt',delimiter='\\t')\n",
    "        return TimeBlocks([\n",
    "            (TimeBlock(id=row.get(\"id\"),\n",
    "                       start_time=datetime.strptime(row.get(\"start_time\"), '%H:%M:%S').time(),\n",
    "                       end_time=datetime.strptime(row.get(\"end_time\"), '%H:%M:%S').time(),\n",
    "                       demand_key_code=row.get(\"demand_key_code\")))\n",
    "            for index, row in df_time_block.iterrows()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv = pd.read_feather('df_mv.feather')\n",
    "df_mv_ctg = pd.read_feather('df_mv_ctg.feather')\n",
    "df_ctg = pd.read_feather('df_ctg.feather')\n",
    "df_ctg_tb = pd.read_feather('df_ctg_tb.feather')\n",
    "\n",
    "date_format = \"%Y-%m-%d\"\n",
    "train_start_date = datetime.strptime(\"2021-01-01\", date_format).date()\n",
    "train_end_date = datetime.strptime(\"2023-05-31\", date_format).date()\n",
    "wards = [\"nursingW2\", \"nursingW3\", \"nursingW4\", \"nursingW5\", \"nursingW7\", \"nursingIcu\", \"nursingW12\", \"nursingW13\",\n",
    "             \"nursingW10\", \"nursingW11\"]\n",
    "customer_code = \"STGAH_LDF_220729\"\n",
    "time_blocks = load_time_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "# TODO: Please revise the below functions to make aggregate_patient_category_v1 run faster\n",
    "def time_blocks_spanned_v1(start_dt: datetime, end_dt: datetime,\n",
    "                            time_block_to_start_time: Dict[str, time]) -> List[Tuple[date, str]]:\n",
    "        if end_dt < start_dt:\n",
    "            return []\n",
    "\n",
    "        start_date = start_dt.date()\n",
    "        end_date = end_dt.date()\n",
    "        start_time = start_dt.time()\n",
    "        end_time = end_dt.time()\n",
    "\n",
    "        tb_spanned = []\n",
    "        if start_date == end_date:\n",
    "            for time_block, time_block_start in time_block_to_start_time.items():\n",
    "                if start_time <= time_block_start <= end_time:\n",
    "                    tb_spanned.append((start_date, time_block))\n",
    "            return tb_spanned\n",
    "\n",
    "        # start_date strictly smaller than end_date\n",
    "        date_rng = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "        for the_date in date_rng[1:-1]:\n",
    "            for time_block in time_block_to_start_time:\n",
    "                tb_spanned.append((the_date.date(), time_block))\n",
    "        for time_block, time_block_start in time_block_to_start_time.items():\n",
    "            if start_time <= time_block_start:\n",
    "                tb_spanned.append((start_date, time_block))\n",
    "            if end_time >= time_block_start:\n",
    "                tb_spanned.append((end_date, time_block))\n",
    "\n",
    "        return tb_spanned\n",
    "\n",
    "def __convert_mv_ctg_to_df_v1(row, end_date, time_block_to_start_time):\n",
    "    end_datetime = datetime.combine(end_date, time.max)\n",
    "    if row['category_end_dt'] > end_datetime:\n",
    "        row['category_end_dt'] = end_datetime\n",
    "\n",
    "    tb_spanned = time_blocks_spanned_v1(row['category_start_dt'], row['category_end_dt'],\n",
    "                                                    time_block_to_start_time)\n",
    "\n",
    "    result: pd.DataFrame = pd.DataFrame(columns=['date', 'time_block', 'ward', 'category_id', 'patient_id'])\n",
    "    for the_date, tb in tb_spanned:\n",
    "        result = pd.concat([result, pd.DataFrame(\n",
    "            [[the_date, tb, row.ward, row.patient_category_id, row.patient_id]],\n",
    "            columns=['date', 'time_block', 'ward', 'category_id', 'patient_id'])])\n",
    "\n",
    "    return result\n",
    "\n",
    "async def aggregate_patient_category_v1(df_mv: pd.DataFrame, df_mv_ctg: pd.DataFrame, df_ctg: pd.DataFrame,\n",
    "                                   df_ctg_tb: pd.DataFrame, start_date: date,\n",
    "                                   end_date: date, wards: list,\n",
    "                                   time_blocks: TimeBlocks) -> pd.DataFrame:\n",
    "    df_ctg = df_ctg.drop(columns='name')\n",
    "    df_mv = df_mv.rename(\n",
    "        columns={'start_time': 'movement_start_dt', 'end_time': 'movement_end_dt', 'workspace_code': 'ward'})\n",
    "    df_mv_ctg.rename(columns={'start_date': 'category_start_dt', 'end_date': 'category_end_dt'}, inplace=True)\n",
    "\n",
    "    def clean_start_end_dt(df, start='category_start_dt', end='category_end_dt'):\n",
    "        df = df.sort_values(start)\n",
    "        df[end] = df[start].shift(-1)\n",
    "        df[start] = df[end].shift(1)\n",
    "        return df\n",
    "\n",
    "    df_mv_ctg = df_mv_ctg.groupby('patient_movement_id', as_index=False, group_keys=False).apply(clean_start_end_dt)\n",
    "    df_mv_ctg_merged = pd.merge(df_mv_ctg, df_mv, how='inner', left_on='patient_movement_id', right_on='id')\n",
    "    df_mv_ctg_merged['category_start_dt'].fillna(df_mv_ctg_merged.movement_start_dt, inplace=True)\n",
    "    df_mv_ctg_merged['category_end_dt'].fillna(df_mv_ctg_merged.movement_end_dt, inplace=True)\n",
    "    df_mv_ctg_merged['category_start_dt'] = df_mv_ctg_merged[['category_start_dt', 'movement_start_dt']].max(axis=1)\n",
    "    df_mv_ctg_merged['category_end_dt'] = df_mv_ctg_merged[['category_end_dt', 'movement_end_dt']].min(axis=1)\n",
    "\n",
    "    # add datetime filter\n",
    "    min_datetime = datetime.combine(start_date, time.min)\n",
    "    max_datetime = datetime.combine(end_date, time.max)\n",
    "    df_mv_ctg_merged = df_mv_ctg_merged[\n",
    "        (df_mv_ctg_merged.category_start_dt <= max_datetime) & (df_mv_ctg_merged.category_end_dt >= min_datetime)]\n",
    "\n",
    "    df_mv_ctg_merged = df_mv_ctg_merged[['patient_movement_id', 'patient_type_id', 'patient_category_id', 'patient_id',\n",
    "                                         'ward', 'category_start_dt', 'category_end_dt']]\n",
    "\n",
    "    df_mv_ctg_split = pd.DataFrame(columns=['date', 'time_block', 'ward', 'category_id', 'patient_id'])\n",
    "    time_block_to_start_time = time_blocks.get_time_block_to_start_time()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for idx, row in df_mv_ctg_merged.iterrows():\n",
    "            futures.append(executor.submit(__convert_mv_ctg_to_df_v1, row, end_date, time_block_to_start_time))\n",
    "\n",
    "        for future in futures:\n",
    "            df_mv_ctg_split = pd.concat([df_mv_ctg_split, future.result()])\n",
    "\n",
    "    df_mv_ctg_split.drop_duplicates(inplace=True)\n",
    "    df_mv_ctg_split['date'] = pd.to_datetime(df_mv_ctg_split.date)\n",
    "    df_mv_ctg_split['category_id'] = pd.to_numeric(df_mv_ctg_split.category_id)\n",
    "    df_mv_ctg_split['patient_id'] = pd.to_numeric(df_mv_ctg_split.patient_id)\n",
    "\n",
    "    df_mv_ctg_agg = df_mv_ctg_split.groupby(['date', 'time_block', 'ward', 'category_id'], as_index=False)[\n",
    "        'patient_id'].nunique()\n",
    "    df_mv_ctg_agg.rename(columns={'patient_id': 'patient_volume'}, inplace=True)\n",
    "\n",
    "    date_rng = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    category_idx = df_ctg.id\n",
    "\n",
    "    index = pd.MultiIndex.from_product([date_rng, time_blocks.get_time_block_ids(), wards, category_idx],\n",
    "                                       names=['date', 'time_block', 'ward', 'category_id'])\n",
    "    df_ctg_agg_full = pd.DataFrame(index=index).reset_index()\n",
    "    df_ctg_agg_full = pd.merge(df_ctg_agg_full, df_ctg, how='left', left_on='category_id', right_on='id')\n",
    "    df_ctg_agg_full = df_ctg_agg_full[['date', 'time_block', 'ward', 'patient_type_id', 'category_id']]\n",
    "    df_mv_ctg_agg = pd.merge(df_ctg_agg_full, df_mv_ctg_agg, how='left')\n",
    "    df_mv_ctg_agg['patient_volume'].fillna(0, inplace=True)\n",
    "\n",
    "    # add in workload hours\n",
    "    df_ctg_tb['time_block_id'] = df_ctg_tb['time_block_id'].astype(str)\n",
    "    df_mv_ctg_agg = df_mv_ctg_agg.merge(df_ctg_tb, how='left', left_on=['category_id', 'time_block'],\n",
    "                                        right_on=['patient_category_id', 'time_block_id'])\n",
    "    df_mv_ctg_agg['cat_total_time_per_nurse_h'] = df_mv_ctg_agg['required_time'] * df_mv_ctg_agg['patient_volume']\n",
    "    df_mv_ctg_agg = df_mv_ctg_agg[['date', 'time_block', 'ward', 'patient_type_id', 'category_id', 'patient_volume',\n",
    "                                   'cat_total_time_per_nurse_h']]\n",
    "    #fill them as 0 first\n",
    "    df_mv_ctg_agg['cat_total_time_per_nurse_h'].fillna(0, inplace=True)\n",
    "\n",
    "    print(f\"Prepared patient categories, size: {len(df_mv_ctg_agg)}\")\n",
    "\n",
    "    return df_mv_ctg_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await aggregate_patient_category_v1(df_mv, df_mv_ctg, df_ctg, df_ctg_tb, train_start_date, train_end_date, wards, time_blocks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We improved the code by optimizing the aggregation of patient data based on categories and time blocks. By processing each date only once, we follow these steps:\n",
    "\n",
    "- Maintain a set of rows in `df_mv_ctg_merged` \n",
    "- Sort the `category_start_date`, `category_end_date`, as well as the timeblocks in an ascending order within a list\n",
    "- Iterate through the sorted list:\n",
    "    - If it matches category_start_date, add that row to the set.\n",
    "    - If it matches category_end_date, remove that row from the set.\n",
    "    - If it matches the time blocks, extend the result with existing rows in the set.\n",
    "\n",
    "This approach eliminates the need for concurrent threads, significantly reducing resource consumption. We conducted tests on my machine, and the results are impressive. The first implementation took approximately 30 minutes to complete, while the optimized version only took around 25 seconds. Importantly, the results from the optimized solution have been validated and are equivalent to those obtained from the initial implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared patient categories, size: 1162920\n"
     ]
    }
   ],
   "source": [
    "async def aggregate_patient_category_v2(df_mv: pd.DataFrame, df_mv_ctg: pd.DataFrame, df_ctg: pd.DataFrame,\n",
    "                                   df_ctg_tb: pd.DataFrame, start_date: date,\n",
    "                                   end_date: date, wards: list,\n",
    "                                   time_blocks: TimeBlocks) -> pd.DataFrame:\n",
    "    df_ctg = df_ctg.drop(columns='name')\n",
    "    df_mv = df_mv.rename(\n",
    "        columns={'start_time': 'movement_start_dt', 'end_time': 'movement_end_dt', 'workspace_code': 'ward'})\n",
    "    df_mv_ctg.rename(columns={'start_date': 'category_start_dt', 'end_date': 'category_end_dt'}, inplace=True)\n",
    "\n",
    "    def clean_start_end_dt(df, start='category_start_dt', end='category_end_dt'):\n",
    "        df = df.sort_values(start)\n",
    "        df[end] = df[start].shift(-1)\n",
    "        df[start] = df[end].shift(1)\n",
    "        return df\n",
    "\n",
    "    df_mv_ctg = df_mv_ctg.groupby('patient_movement_id', as_index=False, group_keys=False).apply(clean_start_end_dt)\n",
    "    df_mv_ctg_merged = pd.merge(df_mv_ctg, df_mv, how='inner', left_on='patient_movement_id', right_on='id')\n",
    "    df_mv_ctg_merged['category_start_dt'].fillna(df_mv_ctg_merged.movement_start_dt, inplace=True)\n",
    "    df_mv_ctg_merged['category_end_dt'].fillna(df_mv_ctg_merged.movement_end_dt, inplace=True)\n",
    "    df_mv_ctg_merged['category_start_dt'] = df_mv_ctg_merged[['category_start_dt', 'movement_start_dt']].max(axis=1)\n",
    "    df_mv_ctg_merged['category_end_dt'] = df_mv_ctg_merged[['category_end_dt', 'movement_end_dt']].min(axis=1)\n",
    "\n",
    "    # add datetime filter\n",
    "    min_datetime = datetime.combine(start_date, time.min)\n",
    "    max_datetime = datetime.combine(end_date, time.max)\n",
    "    df_mv_ctg_merged = df_mv_ctg_merged[\n",
    "        (df_mv_ctg_merged.category_start_dt <= max_datetime) & (df_mv_ctg_merged.category_end_dt >= min_datetime)]\n",
    "\n",
    "    df_mv_ctg_merged = df_mv_ctg_merged[['patient_movement_id', 'patient_type_id', 'patient_category_id', 'patient_id',\n",
    "                                         'ward', 'category_start_dt', 'category_end_dt']]\n",
    "    \n",
    "    time_block_to_start_time = time_blocks.get_time_block_to_start_time()\n",
    "\n",
    "    ###----------------------------------------------------------------------------------------------------------------\n",
    "    ###----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    from datetime import timedelta\n",
    "    df_mv_ctg_merged['index'] = df_mv_ctg_merged.index\n",
    "    start_times = df_mv_ctg_merged[df_mv_ctg_merged['category_start_dt'] <= df_mv_ctg_merged['category_end_dt']][['index','category_start_dt']].values.tolist()\n",
    "    start_times = [x + [0] for x in start_times]\n",
    "    end_times = df_mv_ctg_merged[df_mv_ctg_merged['category_start_dt'] <= df_mv_ctg_merged['category_end_dt']][['index','category_end_dt']].values.tolist()\n",
    "    end_times = [x + [2] for x in end_times]\n",
    "    total_times = start_times + end_times \n",
    "    total_times_date = list(set([x[1].date() for x in total_times]))\n",
    "    total_times_date = [[tb, datetime.combine(x, tb_start_time), 1] for x in total_times_date for tb, tb_start_time in time_block_to_start_time.items()]\n",
    "    total_times = sorted(total_times + total_times_date, key=lambda x: (x[1], x[2]))\n",
    "\n",
    "\n",
    "    current_time = total_times[0][1]\n",
    "    time_interval_stack = set()\n",
    "    result = []\n",
    "\n",
    "    for i, timestamp in enumerate(total_times):\n",
    "        if i and timestamp[1].date() != total_times[i-1][1].date():\n",
    "            current_time = current_time + timedelta(days=1)\n",
    "\n",
    "        while current_time.date() < timestamp[1].date():\n",
    "            result.extend([[current_time.date(), tb, x] for tb in time_block_to_start_time for x in time_interval_stack])\n",
    "            current_time = current_time + timedelta(days=1)\n",
    "        if timestamp[2] == 0:\n",
    "            time_interval_stack.add(timestamp[0])\n",
    "        elif timestamp[2] == 2:\n",
    "            time_interval_stack.remove(timestamp[0])\n",
    "        else:\n",
    "            result.extend([[current_time.date(), timestamp[0], x] for x in time_interval_stack])\n",
    "\n",
    "    df_mv_ctg_split = pd.DataFrame(result, columns=['date', 'time_block', 'index'])\n",
    "    df_mv_ctg_split = df_mv_ctg_split.merge(df_mv_ctg_merged, how='inner', left_on='index', right_on='index')\n",
    "    df_mv_ctg_merged.drop(columns='index', inplace=True)\n",
    "\n",
    "    df_mv_ctg_split = df_mv_ctg_split[['date', 'time_block', 'ward', 'patient_category_id', 'patient_id']]\n",
    "    df_mv_ctg_split.rename(columns={'patient_category_id': 'category_id'}, inplace=True)\n",
    "    \n",
    "    ###----------------------------------------------------------------------------------------------------------------\n",
    "    ###----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    df_mv_ctg_split.drop_duplicates(inplace=True)\n",
    "    df_mv_ctg_split['date'] = pd.to_datetime(df_mv_ctg_split.date)\n",
    "    df_mv_ctg_split['category_id'] = pd.to_numeric(df_mv_ctg_split.category_id)\n",
    "    df_mv_ctg_split['patient_id'] = pd.to_numeric(df_mv_ctg_split.patient_id)\n",
    "\n",
    "    df_mv_ctg_agg = df_mv_ctg_split.groupby(['date', 'time_block', 'ward', 'category_id'], as_index=False)[\n",
    "        'patient_id'].nunique()\n",
    "    df_mv_ctg_agg.rename(columns={'patient_id': 'patient_volume'}, inplace=True)\n",
    "\n",
    "    date_rng = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    category_idx = df_ctg.id\n",
    "\n",
    "    index = pd.MultiIndex.from_product([date_rng, time_blocks.get_time_block_ids(), wards, category_idx],\n",
    "                                       names=['date', 'time_block', 'ward', 'category_id'])\n",
    "    df_ctg_agg_full = pd.DataFrame(index=index).reset_index()\n",
    "    df_ctg_agg_full = pd.merge(df_ctg_agg_full, df_ctg, how='left', left_on='category_id', right_on='id')\n",
    "    df_ctg_agg_full = df_ctg_agg_full[['date', 'time_block', 'ward', 'patient_type_id', 'category_id']]\n",
    "    df_mv_ctg_agg = pd.merge(df_ctg_agg_full, df_mv_ctg_agg, how='left')\n",
    "    df_mv_ctg_agg['patient_volume'].fillna(0, inplace=True)\n",
    "\n",
    "    # add in workload hours\n",
    "    df_ctg_tb['time_block_id'] = df_ctg_tb['time_block_id'].astype(str)\n",
    "    df_mv_ctg_agg = df_mv_ctg_agg.merge(df_ctg_tb, how='left', left_on=['category_id', 'time_block'],\n",
    "                                        right_on=['patient_category_id', 'time_block_id'])\n",
    "    df_mv_ctg_agg['cat_total_time_per_nurse_h'] = df_mv_ctg_agg['required_time'] * df_mv_ctg_agg['patient_volume']\n",
    "    df_mv_ctg_agg = df_mv_ctg_agg[['date', 'time_block', 'ward', 'patient_type_id', 'category_id', 'patient_volume',\n",
    "                                   'cat_total_time_per_nurse_h']]\n",
    "    #fill them as 0 first\n",
    "    df_mv_ctg_agg['cat_total_time_per_nurse_h'].fillna(0, inplace=True)\n",
    "\n",
    "    print(f\"Prepared patient categories, size: {len(df_mv_ctg_agg)}\")\n",
    "\n",
    "    return df_mv_ctg_agg\n",
    "\n",
    "revised_result = await aggregate_patient_category_v2(df_mv, df_mv_ctg, df_ctg, df_ctg_tb, train_start_date, train_end_date, wards, time_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revised_result = revised_result.sort_values(['date','time_block','ward','patient_type_id','category_id','patient_volume','cat_total_time_per_nurse_h'])\n",
    "result = result.sort_values(['date','time_block','ward','patient_type_id','category_id','patient_volume','cat_total_time_per_nurse_h'])\n",
    "\n",
    "result.equals(revised_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization potential can be significantly enhanced through the utilization of vectorization, list comprehension, Cython, or Numba. However, implementing these approaches necessitates intricate modifications to the code, and due to time constraints, further optimization efforts will be discontinued at this point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2f76ae0342d0d8e138d7b9f01e688e783adfb67c5401e5fbe0947b36ee06d4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
